{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erklären den Begriff der bedingten Wahrscheinlichkeit und präsentieren vier Formeln für den Umgang damit.\n",
    "Deren Herleitung ist einfach, aber die Anwendung ist verwirrend und liefert überraschende Ergebnisse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedingte Wahrscheinlichkeit\n",
    "\n",
    "$\\frac{\\partial x_3}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}+\\frac{\\partial x_3}{\\partial x_2}\\cdot\\frac{\\partial x_2}{\\partial x_0}$\n",
    "\n",
    "\n",
    "$\\frac{\\partial x_5}{\\partial x_3}\\cdot(\\frac{\\partial x_3}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}+\\frac{\\partial x_3}{\\partial x_2}\\cdot(\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}))+\\frac{\\partial x_5}{\\partial x_4}\\cdot(\\frac{\\partial x_4}{\\partial x_2}\\cdot(\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0})+\\frac{\\partial x_4}{\\partial x_3}\\cdot(\\frac{\\partial x_3}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}+\\frac{\\partial x_3}{\\partial x_2}\\cdot(\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0})))$\n",
    "\n",
    "$\\frac{\\partial x_1}{\\partial x_0}$\n",
    "$\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}$\n",
    "$\\frac{\\partial x_3}{\\partial x_2}\\cdot\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}$\n",
    "$\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}$\n",
    "$\\frac{\\partial x_3}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}+\\frac{\\partial x_3}{\\partial x_2}\\cdot\\frac{\\partial x_2}{\\partial x_0}$\n",
    "$\\frac{\\partial x_3}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}+\\frac{\\partial x_3}{\\partial x_2}\\cdot(\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0})$\n",
    "$\\frac{\\partial x_5}{\\partial x_3}\\cdot(\\frac{\\partial x_3}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}+\\frac{\\partial x_3}{\\partial x_2}\\cdot(\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}))+\\frac{\\partial x_5}{\\partial x_4}\\cdot(\\frac{\\partial x_4}{\\partial x_2}\\cdot(\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0})+\\frac{\\partial x_4}{\\partial x_3}\\cdot(\\frac{\\partial x_3}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0}+\\frac{\\partial x_3}{\\partial x_2}\\cdot(\\frac{\\partial x_2}{\\partial x_0}+\\frac{\\partial x_2}{\\partial x_1}\\cdot\\frac{\\partial x_1}{\\partial x_0})))$\n",
    "\n",
    "\n",
    "Es seien $A$ und $B$ zwei Ereignisse mit $P(B) > 0$.\n",
    "Die bedingte Wahrscheinlichkeit von $A$ unter $B$ ist definiert durch\n",
    "\n",
    "$$ P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "Wenn $A$ und $B$ unabhängig sind, also $ P(A \\cap B)  = P(A) \\cdot P(B) $, dann ist \n",
    "$P(A|B) = P(A)$, was besagt, dass das Ereignis $B$ das Ereignis $A$ nicht beeinflusst.\n",
    "\n",
    "Die Idee der bedingten Wahrscheinlichkeit ist die Einschränkung der Grundgesamtheit. Beispiel: Es sei $W$ die Zahl, die ein Würfel zeigt, also $P(W = n) = 1/6$ für $n = 1 \\ldots 6$. Wenn bereits bekannt ist, dass $W > 3$, dann verteilt sich die Wahrscheinlichkeit auf die Zahlen $4, 5,6$, also z.B.  $P(W = 6|W >3) = P(W > 3 \\land W =6) / P(W > 3) = 1/3$. Wenn man etwa über Lebenserwartung spricht, dann wird die Grundgesamtheit im Text, außerhalb der Formeln, erklärt, z.B. die Bevölkerung von Deutschland, von Europa oder der Welt. \n",
    "\n",
    "Es sei $M =$ Person ist männlich, $F = $ Person ist weiblich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 94]\n",
      " [100]\n",
      " [141]\n",
      " [150]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test(): \n",
    "    origin = np.array([2, 3, 47, 50])\n",
    "    org = np.outer(origin[0:2], origin[2:4]).reshape(4,1)\n",
    "    print (org)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satz von Bayes (einfach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Satz von Bayes besagt:\n",
    "\n",
    "$$ P(A|B) = P(A) \\cdot \\frac{P(B|A)}{P(B)} $$\n",
    "\n",
    "Der Quotient $P(B|A)/P(B)$ ist ein Maß dafür, wie stark das Ereignis $B$ das Ereignis $A$ beeinflusst.\n",
    "\n",
    "Ein Beispiel: Wir betrachten eine bestimmte Population, z.B. alle Männer in Bayern über vierzig. Wir haben zwei Informationen:\n",
    "\n",
    "* 40% der betrachteten Population sind Raucher.\n",
    "* In einer Stichprobe von 1000 Patienten mit Lungenkrebs waren 990 Raucher. \n",
    "\n",
    "Die Frage lautet: Um welchen Faktor erhöht Rauchen das Risiko für Lungenkrebs? Wir setzen $A =$ \"Person ist Raucher\" und $B = $ \"Person hat Lungenkrebs\". Wir kennen $P(A) = 0,4$ und $P(A|B) = 0,99$, also die Wahrscheinlichkeit dafür, dass jemand mit Lungenkrebs Raucher war. Den Raucher interessiert aber etwas anderes, nämlich die Wahrscheinlichkeit dafür, dass er Lungenkrebs bekommt. Mit Bayes ergibt sich:\n",
    "\n",
    "$$ P(B|A) = P(B) \\cdot \\frac{P(A|B)}{P(A)} = P(B) \\cdot \\frac{0,99}{0,4} \\approx P(B) \\cdot 2,5 $$\n",
    "\n",
    "Ergebnis: Die vernichtende Statistik (fast jeder Lungenkrebspatient war Raucher) erlaubt bei einem Raucheranteil von 40% den Schluss, dass sich das Risiko für Lungenkrebs um den Faktor 2,5 erhöht. Das Ergebnis ändert sich fast nicht, wenn wir annehmen, dass alle Krebspatinenten Raucher waren, aber es ändert sich massiv, wenn wir den Raucheranteil reduzieren: Bie 10% Rauchern ($P(A) = 0,1$) erhalten wir den Faktor 10, bei 1% ($P(A) = 0,01$) den Faktor 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Bayessche Kettenregel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Bayessche Kettenregel ist die Grundlage von Bayesschen Netzen. Sie lautet:\n",
    "\n",
    "$$ P(A_1 \\cap \\cdots \\cap A_n) =  P(A_1)\\cdot P(A_2|A_1) \\cdot P(A_3|A_1 \\cap A_2) \\cdots P(A_n|A_1 \\cap \\cdots \\cap A_{n-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satz von der totalen Wahrscheinlichkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oft kann man ein Ereignis $A$ in disjunkte Fälle $B_1, B_2, \\cdots B_n$ zerlegen. In diesem Fall gilt:\n",
    "\n",
    "$$ P(A) = \\sum_{i=1}^n    P(A|B_i) \\cdot P(B_i) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Satz von Bayes (allgemein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ereignis $A$ sei wieder in disjunkte Fälle  $B_1, B_2, \\cdots B_n$ zerlegt. Interpretation: $B_k$ ist eine von $n$ möglichen Ursachen von $A$. Der allgemeine Satz von Bayes liefert die Wahrscheinlichkeit für die Ursache $B_k$, wenn $A$ eingetreten ist:\n",
    "\n",
    "$$ P(B_k|A) = P(B_k) \\cdot \\frac{P(A|B_k)}{\\sum_{i=1}^n P(A|B_i) \\cdot P(B_i) } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messungen und Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gegeben sei ein System mit den beiden Zuständen $A_1$ (normal) und $A_2$ (abweichend). Es ist $P(A_2) = 1 - P(A_1)$. Wir beobachten das System durch eine Anzeige (oder einen Test) mit den möglichen Werten $B_1$ (normal) und $B_2$ (Alarm). Die Qualität der Anzeige sei bekannt: $P(B_1|A_1)$ ist die Zuverlässigkeit im Normalzustand, $P(B_2|A_2)$ sonst. Daraus ergeben sich die Wahrscheinlichkeiten $P(B_2|A_1) = 1 - P(B_1|A_1)$ (Fehlalarm) und $P(B_1|A_2) = 1 - P(B_2|A_2)$ (silent disaster). Diese Werte ermittelt man durch Ausprobieren: Man prüft die Anzeige (oder den Test) in bekannten Situationen und zählt die Falschmeldungen. Der Benutzer, der nur die Anzeige oder das Testergebnis sieht, interessiert sich für die umgekehrten Wahrscheinlichkeiten $P(A_1|B_2)$ (false positive) und $P(A_2|B_1)$ (false negative): Er will wissen, wie gut er der Anzeige oder dem Test trauen kann. Diese allgemeine Situation findet man in zahllosen Varianten, von der Kontolllampe im Auto bis zum Test auf Krebs.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}