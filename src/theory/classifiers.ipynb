{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The General Setting\n",
    "\n",
    ">\\begin{equation}\n",
    "\\begin{split}\n",
    "m &= \\text{number of documents: }{doc}_1, \\ldots, {doc}_m \\\\\n",
    "n &= \\text{number of different words: }{word}_1, \\ldots, {word}_n \\\\\n",
    "K &= \\text{number of classes: }{class}_1, \\ldots, {class}_K \\\\\n",
    "\\\\\n",
    "X &= [x_{ij} : count({word}_j) \\text{ in } {doc}_i]_{\\substack{\n",
    "            i = 1, \\ldots, m\\\\\n",
    "            j = 1, \\ldots, n}} \\\\\n",
    "rowsum(X) & = [count(words) \\text{ in } {doc}_i]_{i = 1, \\ldots, m} \\\\\n",
    "colsum(X) & = [count({word}_j) \\text{ in } docs]_{j = 1, \\ldots, n} \\\\\n",
    "sum(X) & = count(words) \\\\\n",
    "evidence(X) & = P[word = {word}_j]_{j = 1, \\ldots, n} = \\frac{colsum(X)}{sum(X)} \\\\\n",
    "sum(evidence(X)) & = 1 \\\\\n",
    "\\\\\n",
    "Y &= [y_{ik} : \\delta_{k, class({doc}_i)}]_{\\substack{\n",
    "            i = 1, \\ldots, m \\\\\n",
    "            k = 1, \\ldots, K}} \\\\\n",
    "rowsum(Y) & = ones(m) \\\\\n",
    "colsum(Y) & = [count(docs) \\text{ in } {class}_k]_{k = 1, \\ldots, K} \\\\\n",
    "sum(Y) & = count(docs) \\\\\n",
    "prior(Y) &= P[class = {class}_k]_{k = 1, \\ldots, K} = \\frac{colsum(Y)}{sum(Y)} \\\\\n",
    "sum(prior(Y)) & = 1 \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayesian Classifier\n",
    "\n",
    ">\\begin{equation}\n",
    "\\begin{split}\n",
    "C = Y^TX &= [c_{kj} : count({word}_j) \\text{ in docs of } class_k]_{\\substack{\n",
    "            k = 1, \\ldots, K\\\\\n",
    "            j = 1, \\ldots, n}} \\\\\n",
    "rowsum(C) & = [count(words) \\text{ in docs of } {class}_k]_{k = 1, \\ldots, K} \\\\\n",
    "colsum(C) & = [count({word}_j) \\text{ in docs of } classes]_{j = 1, \\ldots, n} \\\\\n",
    "sum(C) & = count(words) \\\\\n",
    "likelihood(C) &= P[word = {word}_j | class = {class}_k]_{\\substack{\n",
    "            k = 1, \\ldots, K\\\\\n",
    "            j = 1, \\ldots, n}} = \\frac{C}{rowsum(C)}\\\\\n",
    "\\\\\n",
    "rowsum(likelihood(C)) & = ones(K) \\\\\n",
    "\\\\\n",
    "posterior(x) &= P[class = {class}_k | count({word}_j) = x_j\n",
    "\\text{ for } j = 1, \\ldots, n]_{k = 1, \\ldots, K}   \\\\\n",
    "&= \\Big[\n",
    "prior_k \\cdot \\prod_{j = 1}^n P[word = {word}_j | class = {class}_k]^{x_j}\n",
    "\\Big]_{k = 1, \\ldots, K} \\\\\n",
    "&\\qquad \\cdot\\Big[ \\prod_{j = 1}^n P[word = {word}_j]\\Big]^{-1} \\\\\n",
    "\\\\\n",
    "\\log posterior(x) & = \\Big[\n",
    "\\log prior_k + \\sum_{j = 1}^n x_j \\log P[word = {word}_j | class = {class}_k]\n",
    "\\Big]_{k = 1, \\ldots, K}\n",
    "\\\\ & \\qquad - \\sum_{j = 1}^n \\log P[word = {word}_j] \\\\\n",
    "&= \\log prior + (\\log likelihood) \\cdot x  - (\\log evidence) \\cdot ones(n)\\\\\n",
    "prediction(x) &= \\underset{k = 1, \\ldots, K}{arg max} (\\log posterior(x))  \\\\\n",
    "\\\\\n",
    "posterior(X) &= [posterior(x_{i, *})]_{i = 1, \\ldots, m} \\\\\n",
    "\\log posterior(X) &= [\\log posterior(x_{i, *})]_{i = 1, \\ldots, m} = b + XW^T - const\\\\\n",
    "prediction(X) &= [prediction(x_{i, *})]_{i = 1, \\ldots, m} \\\\\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
